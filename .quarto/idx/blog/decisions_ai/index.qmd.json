{"title":"Decisions and the future of AI","markdown":{"yaml":{"title":"Decisions and the future of AI","subtitle":"The problem of human preferences","date":"2025-09-21","conference":"","categories":["artificial intelligence","technology","choices"],"author":["Harry Aquije Ballon"]},"headingText":"Every decision matters","containsRefs":false,"markdown":"\n  \n<div class=\"talk-figure\">\n  <div class=\"figure-title\"></div>\n  \n  ![Source: Image generated using Stable Diffusion 3](2081948413.png){.talk-image}\n\n</div>\n\n  \nEvery day we face decisions about small things and events that can change our lives. How to make the right choice can be explained by self-interest or as stated by the rational model of economics, consumers seek to maximize preferences.\n\nAs we interact in society, we want to compare preferences across individuals and establish rankings. This can serve different purposes, from a marketing point of view, predicting people’s choices allows the design of products matching those preferences and that are more appealing to customers. For policymakers understanding individual preferences allows the design of policies that bring greater value across the population.\n\nArtificial intelligence (AI) is the science to teach machines human-like abilities and with the launch of ChatGPT and similar models — in the last few years — anyone with access to the internet can benefit from it. If used correctly AI can boost productivity and lead to economic progress like never before; however, the risks match the potential gains. As machines become more powerful it can be a risk that they will surpass us.\n\nThe focus has been on large language models that can create human-like content. Originally, researchers trained these models to do specific tasks. For example, face recognition or playing Go. This is known as narrow AI, and on this topic, AI systems have outperformed the best humans. As happened in March 2016 when AlphaGo from DeepMind defeated a world champion, a decade before experts thought possible.\n\n## How to create beneficial AI \n\nAI is advancing faster than any previous technology fuelled by major investments across the world. This evolution could potentially reach what is known as artificial general intelligence, that is the state in which machines can do all human activities. It is someone you can talk to and can do anything, not just one specific thing. We are not there yet, but in this process, machines will face decisions just as we do.\n\nAI expert Stuart Russel in his book Human Compatible AI and the Problem of Control addresses this problem. He proposes that AI researchers, in thinking about how to create beneficial AI, must follow three principles.\n\n1. The machine’s only objective is to maximize the realization of human preferences.  \n2. The machine is initially uncertain about what those preferences are.  \n3. The ultimate source of information about human preferences is human behavior.  \n\nHuman preferences are the foundation for these principles, which takes us back to the individuals’ choice process adding the complexity that machines should learn to understand us. They should do this based on the observation of our choices, as we do with the rest of the world. Then, they go back to the first principle.\n\n## Conclusion\n\nWe are entering the most revolutionary period ever that will give us a unique chance to shape the world for the better. Progress in AI will continue and speed up in the coming years representing an avenue of growth for advanced and developing economies.\n\nTo ensure AI is beneficial for humans, we need interdisciplinary cooperation between social sciences, philosophy and technology development to set the basis for the new challenges to come and to put humans at the centre of decision-making. We needed this balance throughout history, making beneficial AI will need it too. It's a balance between selfish and selfless.\n\n## References\n\nMcFadden, D., 2001. Economic choices. American economic review, 91(3), pp.351-378.\n\nRussell, S., 2019. Human compatible: AI and the problem of control. Penguin UK.\n\nSuleyman, Mustafa and Michael, Bhaskar. 2023. The Coming Wave: Technology, Power, and the Twenty-first Century's Greatest Dilemma. Crown.\n","srcMarkdownNoYaml":"\n  \n<div class=\"talk-figure\">\n  <div class=\"figure-title\"></div>\n  \n  ![Source: Image generated using Stable Diffusion 3](2081948413.png){.talk-image}\n\n</div>\n\n## Every decision matters\n  \nEvery day we face decisions about small things and events that can change our lives. How to make the right choice can be explained by self-interest or as stated by the rational model of economics, consumers seek to maximize preferences.\n\nAs we interact in society, we want to compare preferences across individuals and establish rankings. This can serve different purposes, from a marketing point of view, predicting people’s choices allows the design of products matching those preferences and that are more appealing to customers. For policymakers understanding individual preferences allows the design of policies that bring greater value across the population.\n\nArtificial intelligence (AI) is the science to teach machines human-like abilities and with the launch of ChatGPT and similar models — in the last few years — anyone with access to the internet can benefit from it. If used correctly AI can boost productivity and lead to economic progress like never before; however, the risks match the potential gains. As machines become more powerful it can be a risk that they will surpass us.\n\nThe focus has been on large language models that can create human-like content. Originally, researchers trained these models to do specific tasks. For example, face recognition or playing Go. This is known as narrow AI, and on this topic, AI systems have outperformed the best humans. As happened in March 2016 when AlphaGo from DeepMind defeated a world champion, a decade before experts thought possible.\n\n## How to create beneficial AI \n\nAI is advancing faster than any previous technology fuelled by major investments across the world. This evolution could potentially reach what is known as artificial general intelligence, that is the state in which machines can do all human activities. It is someone you can talk to and can do anything, not just one specific thing. We are not there yet, but in this process, machines will face decisions just as we do.\n\nAI expert Stuart Russel in his book Human Compatible AI and the Problem of Control addresses this problem. He proposes that AI researchers, in thinking about how to create beneficial AI, must follow three principles.\n\n1. The machine’s only objective is to maximize the realization of human preferences.  \n2. The machine is initially uncertain about what those preferences are.  \n3. The ultimate source of information about human preferences is human behavior.  \n\nHuman preferences are the foundation for these principles, which takes us back to the individuals’ choice process adding the complexity that machines should learn to understand us. They should do this based on the observation of our choices, as we do with the rest of the world. Then, they go back to the first principle.\n\n## Conclusion\n\nWe are entering the most revolutionary period ever that will give us a unique chance to shape the world for the better. Progress in AI will continue and speed up in the coming years representing an avenue of growth for advanced and developing economies.\n\nTo ensure AI is beneficial for humans, we need interdisciplinary cooperation between social sciences, philosophy and technology development to set the basis for the new challenges to come and to put humans at the centre of decision-making. We needed this balance throughout history, making beneficial AI will need it too. It's a balance between selfish and selfless.\n\n## References\n\nMcFadden, D., 2001. Economic choices. American economic review, 91(3), pp.351-378.\n\nRussell, S., 2019. Human compatible: AI and the problem of control. Penguin UK.\n\nSuleyman, Mustafa and Michael, Bhaskar. 2023. The Coming Wave: Technology, Power, and the Twenty-first Century's Greatest Dilemma. Crown.\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"markdown"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","output-file":"index.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.7.32","publish":{"type":"quarto-pub","name":"harry-aquije-ballon-blog-2025-newaccount"},"theme":["cosmo","../../styles.scss"],"date-format":"YYYY-MM-DD","listing":{"type":"default","contents":"..","sort":"date desc","fields":["date","title","conference","categories"],"page-size":10},"template-partials":["../title-block.html"],"title":"Decisions and the future of AI","subtitle":"The problem of human preferences","date":"2025-09-21","conference":"","categories":["artificial intelligence","technology","choices"],"author":["Harry Aquije Ballon"]},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}